{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Tensor基础\n",
    "- 0: scalar\n",
    "- 1: vector\n",
    "- 2: matrix\n",
    "- 3: n-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Scalar\n",
    "\n",
    "通常就是一个数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(42.), 0, 42.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tensor(42.)\n",
    "scalar, scalar.dim(), scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Vector\n",
    "例如：[-5., 2., 0.], 在深度学习中通常只特征，例如词向量特征，某一维特征等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5000, -0.5000,  3.0000]), 1, torch.Size([3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tensor([1.5, -0.5, 3.0])\n",
    "vector, vector.dim(), vector.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Matrix\n",
    "一般计算的都是矩阵，通常都是多维的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7., 10.],\n",
       "         [15., 22.]]),\n",
       " tensor([1., 2.]),\n",
       " tensor([[ 1.,  4.],\n",
       "         [ 9., 16.]]),\n",
       " tensor([ 7., 10.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tensor([[1., 2.],[3., 4.]])\n",
    "matrix.matmul(matrix), tensor([1., 0.]).matmul(matrix), matrix * matrix, tensor([1., 2.]).matmul(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 线性回归模型\n",
    "- 线性回归模型就是一个不加激活函数的全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定参数和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# 创建损失函数\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 1), (11, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype = np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype = np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch50, loss0.024922925978899002\n",
      "epoch100, loss0.014215030707418919\n",
      "epoch150, loss0.008107777684926987\n",
      "epoch200, loss0.004624378867447376\n",
      "epoch250, loss0.0026375409215688705\n",
      "epoch300, loss0.0015043760649859905\n",
      "epoch350, loss0.0008580290013924241\n",
      "epoch400, loss0.0004893920267932117\n",
      "epoch450, loss0.000279134139418602\n",
      "epoch500, loss0.00015920335135888308\n",
      "epoch550, loss9.080698509933427e-05\n",
      "epoch600, loss5.1790630095638335e-05\n",
      "epoch650, loss2.9537959562730975e-05\n",
      "epoch700, loss1.6848685845616274e-05\n",
      "epoch750, loss9.610754204913974e-06\n",
      "epoch800, loss5.48083289686474e-06\n",
      "epoch850, loss3.1261442927643657e-06\n",
      "epoch900, loss1.782401909622422e-06\n",
      "epoch950, loss1.0167717618969618e-06\n",
      "epoch1000, loss5.798705160486861e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # 转化为tensor\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    labels = torch.from_numpy(y_train)\n",
    "    \n",
    "    # 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新权重参数\n",
    "    optimizer.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch{}, loss{}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9986],\n",
       "        [ 2.9988],\n",
       "        [ 4.9990],\n",
       "        [ 6.9992],\n",
       "        [ 8.9994],\n",
       "        [10.9996],\n",
       "        [12.9998],\n",
       "        [15.0000],\n",
       "        [17.0002],\n",
       "        [19.0004],\n",
       "        [21.0006]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(torch.from_numpy(x_train)).data.numpy()\n",
    "# 如果不使用numpy(), 输出张量\n",
    "# predicted = model(torch.from_numpy(x_train)).data\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的保存与读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "model.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用GPU进行训练\n",
    "- 只需要把数据和模型传入到cuda里面就可以\n",
    "\n",
    "\n",
    "首先验证GPU信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1, 'GeForce RTX 2060 SUPER')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搬迁原有的训练代码至GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch50, loss0.005179176572710276\n",
      "epoch100, loss0.0029540262185037136\n",
      "epoch150, loss0.0016848703380674124\n",
      "epoch200, loss0.000960984209086746\n",
      "epoch250, loss0.0005481111584231257\n",
      "epoch300, loss0.0003126159717794508\n",
      "epoch350, loss0.00017831222794484347\n",
      "epoch400, loss0.0001016985479509458\n",
      "epoch450, loss5.8006004110211506e-05\n",
      "epoch500, loss3.308253508294001e-05\n",
      "epoch550, loss1.8868291590479203e-05\n",
      "epoch600, loss1.0761198609543499e-05\n",
      "epoch650, loss6.137979653431103e-06\n",
      "epoch700, loss3.500336333672749e-06\n",
      "epoch750, loss1.9965177671110723e-06\n",
      "epoch800, loss1.138864263339201e-06\n",
      "epoch850, loss6.497398317151237e-07\n",
      "epoch900, loss3.703109427988238e-07\n",
      "epoch950, loss2.1137333305887296e-07\n",
      "epoch1000, loss1.204232802365368e-07\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "# 将模型传入到GPU中\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# 创建损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # 转化为tensor\n",
    "    inputs = torch.from_numpy(x_train).to(device)\n",
    "    labels = torch.from_numpy(y_train).to(device)\n",
    "    \n",
    "    # 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新权重参数\n",
    "    optimizer.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch{}, loss{}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1):\n",
    "        # 定义\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # embedding层\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Pytorch的RNN层，batch_first标志可以让输入的张量的第一个维度标示batch，有了embedding层，input_size = hidden_size\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers)# , batch_first = True)\n",
    "        # 输出的全连接层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        # 最后的logsoftmax层，考虑如何表现企业的发展预期？是否使用一种分类的打分方法？\n",
    "        # self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        # 运算过程\n",
    "        # size of input：[batch_size, num_step, data_dim]\n",
    "        \n",
    "        # embedding层:\n",
    "        # 从输入到隐含层的计算，可以把一个数值现转化成one-hot向量，再把一个向量转化为hidden_size维的向量\n",
    "        output = self.embedding(input, hidden)\n",
    "        # size of output：[batch_size, num_step, hidden_size]\n",
    "        \n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        # size of output：[batch_size, num_step, hidden_size]\n",
    "      \n",
    "        # 从输出output中取出最后一个时间步的数值，注意output输出包含了所有时间步的结果\n",
    "        output = output[:,-1,:]\n",
    "        # size of output：[batch_size, hidden_size]\n",
    "        \n",
    "        # 全链接层\n",
    "        output = self.linear(output)\n",
    "        # output尺寸为：batch_size, output_size\n",
    "        \n",
    "        # softmax层，归一化处理\n",
    "        # output = self.softmax(output)\n",
    "         # size of output：batch_size, output_size\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入大小是三维tensor[seq_len,batch_size,input_dim]\n",
    "\n",
    "input_dim是输入的维度，比如是128\n",
    "\n",
    "batch_size是一次往RNN输入句子的数目，比如是5。\n",
    "\n",
    "seq_len是一个句子的最大长度，比如15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
