{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN语言预测模型搭建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "10.2\n",
      "7605\n",
      "GeForce RTX 2060 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(30, 256)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征one-hot长度\n",
    "character_num = 30\n",
    "rnn_layer = nn.RNN(input_size = 30, hidden_size = 256)\n",
    "rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_step = 10\n",
    "batch_size = 10\n",
    "state = None\n",
    "X = torch.rand(num_step, batch_size, character_num)\n",
    "Y, state_new = rnn_layer(X, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出形状为(时间步数, 批量大小, 隐藏单元个数)\n",
    "\n",
    "隐藏状态h的形状为(层数, 批量大小, 隐藏单元个数)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10, 30]),\n",
       " torch.Size([10, 10, 256]),\n",
       " torch.Size([1, 10, 256]),\n",
       " 10,\n",
       " torch.Size([10, 256]),\n",
       " tensor([[-0.0936, -0.0315,  0.0873,  ..., -0.1816,  0.1078, -0.2324],\n",
       "         [-0.0406, -0.0799,  0.1188,  ..., -0.1241,  0.2018, -0.1476],\n",
       "         [ 0.0107, -0.1790,  0.0745,  ..., -0.1639,  0.2091, -0.1710],\n",
       "         ...,\n",
       "         [-0.1241,  0.1264,  0.0248,  ..., -0.2317, -0.0206, -0.2070],\n",
       "         [-0.0810, -0.0974,  0.1513,  ..., -0.1183,  0.1855, -0.0925],\n",
       "         [-0.0302, -0.0617,  0.1653,  ..., -0.1378,  0.0241, -0.2368]],\n",
       "        grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, state_new.shape, len(state_new[0]), state_new[0].shape, state_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[9.4706e-01, 1.9844e-01, 5.5712e-01,  ..., 4.2209e-01,\n",
       "           3.8913e-01, 1.4768e-01],\n",
       "          [2.5061e-01, 4.3815e-01, 7.7981e-01,  ..., 8.1407e-01,\n",
       "           2.3869e-01, 6.7847e-01],\n",
       "          [1.4627e-01, 3.3819e-01, 3.3390e-01,  ..., 3.8618e-01,\n",
       "           5.3179e-01, 1.1004e-01],\n",
       "          ...,\n",
       "          [6.5719e-01, 1.0834e-02, 8.3722e-02,  ..., 1.3385e-02,\n",
       "           5.0465e-01, 5.1632e-01],\n",
       "          [3.2952e-01, 8.5258e-04, 5.9652e-01,  ..., 7.0682e-01,\n",
       "           9.0988e-01, 6.9345e-02],\n",
       "          [1.1492e-01, 1.3212e-01, 9.0775e-01,  ..., 6.2126e-02,\n",
       "           6.3409e-01, 6.8484e-01]],\n",
       " \n",
       "         [[4.6834e-01, 2.8110e-01, 1.1637e-01,  ..., 3.1874e-02,\n",
       "           7.7103e-01, 5.3964e-01],\n",
       "          [5.9911e-01, 7.4805e-01, 5.0832e-01,  ..., 4.5969e-01,\n",
       "           5.1753e-01, 8.8499e-01],\n",
       "          [5.7064e-01, 4.4039e-01, 3.5208e-01,  ..., 8.3218e-01,\n",
       "           4.4287e-01, 2.9848e-01],\n",
       "          ...,\n",
       "          [7.8753e-01, 1.2984e-01, 6.0310e-02,  ..., 6.5401e-01,\n",
       "           1.4062e-01, 4.3887e-01],\n",
       "          [8.2064e-01, 2.2992e-01, 8.3902e-01,  ..., 7.9671e-01,\n",
       "           9.7458e-01, 6.0498e-01],\n",
       "          [3.4518e-01, 9.3870e-01, 2.4610e-01,  ..., 5.3556e-01,\n",
       "           4.0043e-01, 2.7076e-01]],\n",
       " \n",
       "         [[6.2043e-01, 6.6279e-01, 9.5234e-01,  ..., 5.8492e-01,\n",
       "           4.8034e-01, 5.3223e-01],\n",
       "          [5.7851e-01, 8.5093e-02, 9.4370e-01,  ..., 1.6635e-01,\n",
       "           3.6044e-01, 3.8587e-01],\n",
       "          [8.9496e-01, 9.3397e-01, 4.3114e-01,  ..., 3.1724e-01,\n",
       "           6.2592e-01, 4.9550e-01],\n",
       "          ...,\n",
       "          [7.4279e-01, 7.2554e-01, 7.9331e-01,  ..., 5.8242e-01,\n",
       "           5.2923e-01, 9.5552e-01],\n",
       "          [1.9660e-01, 9.6777e-02, 5.2506e-01,  ..., 5.9536e-01,\n",
       "           6.5131e-01, 8.5990e-01],\n",
       "          [4.9628e-01, 3.3544e-01, 2.5226e-01,  ..., 8.7107e-01,\n",
       "           6.8378e-01, 3.4327e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[5.2251e-01, 5.6997e-01, 9.4221e-01,  ..., 8.4217e-01,\n",
       "           3.2452e-01, 4.9264e-01],\n",
       "          [1.8645e-01, 3.8262e-01, 5.7640e-01,  ..., 5.3483e-01,\n",
       "           4.5185e-01, 6.8540e-01],\n",
       "          [1.1903e-01, 6.2948e-01, 5.2807e-01,  ..., 5.9116e-01,\n",
       "           5.4066e-01, 8.0533e-01],\n",
       "          ...,\n",
       "          [3.7592e-01, 3.6812e-02, 8.3631e-01,  ..., 2.2425e-01,\n",
       "           3.6521e-01, 1.0907e-01],\n",
       "          [2.0002e-01, 1.0604e-01, 9.9701e-01,  ..., 3.3479e-01,\n",
       "           2.7371e-01, 6.7034e-01],\n",
       "          [5.8054e-01, 4.1672e-01, 7.6643e-01,  ..., 7.4268e-01,\n",
       "           8.5343e-03, 5.2176e-01]],\n",
       " \n",
       "         [[2.1800e-01, 2.3924e-01, 4.9147e-01,  ..., 3.7158e-01,\n",
       "           7.9816e-01, 2.8610e-01],\n",
       "          [8.3536e-01, 6.9902e-01, 7.4572e-02,  ..., 4.6318e-01,\n",
       "           3.0076e-01, 3.9300e-01],\n",
       "          [1.5737e-01, 9.1118e-01, 5.0156e-01,  ..., 7.0394e-01,\n",
       "           6.6480e-01, 8.6194e-01],\n",
       "          ...,\n",
       "          [3.9004e-02, 5.6190e-01, 1.6561e-01,  ..., 2.8755e-01,\n",
       "           9.5551e-01, 8.8064e-01],\n",
       "          [8.0288e-01, 5.0699e-01, 5.6807e-01,  ..., 4.9709e-01,\n",
       "           3.7560e-01, 1.9795e-01],\n",
       "          [7.6426e-01, 9.2487e-01, 9.3664e-01,  ..., 1.9948e-02,\n",
       "           8.3229e-01, 6.0575e-01]],\n",
       " \n",
       "         [[4.9447e-01, 9.6995e-01, 4.9998e-01,  ..., 9.0842e-02,\n",
       "           5.6444e-01, 8.7028e-01],\n",
       "          [8.6247e-01, 3.9537e-01, 3.2630e-01,  ..., 8.6600e-01,\n",
       "           6.7299e-01, 6.3539e-01],\n",
       "          [3.5468e-02, 4.1226e-01, 4.6397e-01,  ..., 5.4512e-01,\n",
       "           7.9353e-01, 5.5486e-01],\n",
       "          ...,\n",
       "          [1.7348e-01, 8.7649e-01, 1.9508e-03,  ..., 3.3852e-02,\n",
       "           3.3699e-01, 5.1882e-01],\n",
       "          [4.0314e-02, 1.8187e-01, 4.9380e-01,  ..., 2.8211e-02,\n",
       "           2.3953e-01, 8.5900e-01],\n",
       "          [3.2600e-01, 9.3896e-01, 1.2317e-01,  ..., 1.4974e-02,\n",
       "           4.2853e-01, 1.0858e-01]]]),\n",
       " tensor([[[-9.5121e-02, -1.0809e-01,  9.6071e-02,  ..., -3.2335e-02,\n",
       "            1.9457e-01, -2.9485e-02],\n",
       "          [-3.6183e-02, -1.7865e-01,  1.6146e-01,  ..., -5.9570e-02,\n",
       "            3.4550e-01, -1.6029e-01],\n",
       "          [ 8.6620e-02, -1.0672e-01,  6.6013e-02,  ..., -3.4018e-02,\n",
       "            4.2868e-02, -8.8533e-02],\n",
       "          ...,\n",
       "          [-4.8515e-02, -1.4121e-01,  1.4853e-01,  ..., -1.5283e-01,\n",
       "            1.7740e-01, -5.6194e-02],\n",
       "          [-5.8209e-02, -6.2698e-02,  4.5671e-02,  ..., -4.0495e-02,\n",
       "            1.1906e-01, -6.8592e-02],\n",
       "          [-1.0102e-01, -1.1531e-01,  8.4709e-02,  ..., -4.0449e-02,\n",
       "            2.0904e-01, -1.0014e-01]],\n",
       " \n",
       "         [[-1.4799e-01, -4.3843e-02,  1.8443e-02,  ..., -5.4191e-02,\n",
       "            7.6596e-02, -1.0642e-01],\n",
       "          [-2.4873e-01,  4.1432e-02,  4.9216e-02,  ..., -1.9191e-01,\n",
       "            2.5299e-01, -2.4078e-01],\n",
       "          [-3.5553e-02, -1.1897e-01,  8.5079e-02,  ..., -6.1395e-02,\n",
       "            2.7965e-01, -1.5373e-01],\n",
       "          ...,\n",
       "          [-1.0322e-01, -1.7392e-04,  9.0917e-02,  ..., -7.4081e-02,\n",
       "            1.6118e-01, -9.5693e-02],\n",
       "          [-1.5357e-01,  1.9009e-02,  4.4304e-02,  ..., -1.7961e-01,\n",
       "            1.2668e-01, -1.0910e-01],\n",
       "          [-8.4041e-02, -4.4693e-02, -2.8147e-02,  ..., -1.6457e-01,\n",
       "            1.1482e-01, -2.7131e-01]],\n",
       " \n",
       "         [[-6.4487e-02,  2.6334e-02,  1.5558e-01,  ..., -7.0918e-02,\n",
       "            4.8511e-02, -9.4697e-02],\n",
       "          [-6.8394e-02, -2.5153e-02,  1.4326e-01,  ..., -4.8496e-02,\n",
       "            1.8236e-01, -1.2005e-01],\n",
       "          [-6.2627e-02, -1.3775e-02,  2.4033e-01,  ..., -1.1745e-01,\n",
       "            3.5452e-02, -1.6148e-01],\n",
       "          ...,\n",
       "          [ 1.2298e-02, -7.0839e-02,  9.9103e-02,  ...,  8.7099e-03,\n",
       "            1.9376e-01, -2.5198e-01],\n",
       "          [-2.5138e-02,  9.3521e-02,  1.5454e-01,  ..., -1.1806e-01,\n",
       "            1.4550e-01, -1.9067e-01],\n",
       "          [-7.2641e-02, -3.3585e-02,  4.1046e-02,  ..., -1.0525e-02,\n",
       "            8.0139e-02,  1.0918e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.8262e-02, -1.4510e-01,  7.8915e-02,  ..., -3.1055e-02,\n",
       "            1.0786e-01, -1.2004e-01],\n",
       "          [-1.1817e-01,  2.2686e-02,  1.3392e-01,  ..., -1.5950e-01,\n",
       "            2.9956e-02, -1.9144e-01],\n",
       "          [-4.1538e-02, -2.6828e-02,  3.3651e-02,  ..., -1.4393e-01,\n",
       "            8.4284e-02, -2.5489e-01],\n",
       "          ...,\n",
       "          [-9.8446e-02,  5.4063e-02,  7.0258e-02,  ..., -1.6046e-01,\n",
       "            1.5254e-01, -1.8023e-01],\n",
       "          [-7.1306e-02, -7.0625e-02,  5.5356e-02,  ..., -4.9787e-03,\n",
       "            2.1345e-01, -1.4330e-01],\n",
       "          [-9.1811e-02, -1.3834e-01,  1.3998e-01,  ..., -2.0983e-01,\n",
       "            2.6202e-01, -1.4857e-01]],\n",
       " \n",
       "         [[-1.6112e-01,  7.8459e-02, -1.7478e-03,  ..., -1.4349e-01,\n",
       "            1.8174e-02, -2.6919e-01],\n",
       "          [ 3.0087e-02, -1.2555e-01,  1.0455e-01,  ..., -1.2835e-01,\n",
       "            1.9354e-01, -9.0540e-02],\n",
       "          [ 8.5336e-03,  7.4836e-02,  9.3247e-02,  ..., -7.6185e-03,\n",
       "            6.5933e-02, -7.7899e-02],\n",
       "          ...,\n",
       "          [-1.1156e-01, -9.5907e-02, -3.4449e-02,  ..., -7.7863e-02,\n",
       "            2.4949e-02, -8.8789e-02],\n",
       "          [-1.5584e-01,  9.7482e-02,  1.1511e-01,  ..., -2.0954e-02,\n",
       "            9.6484e-02, -6.0011e-02],\n",
       "          [-1.2844e-01, -7.2421e-02,  6.9529e-02,  ..., -1.1180e-01,\n",
       "            2.0031e-01, -1.6470e-01]],\n",
       " \n",
       "         [[-9.3562e-02, -3.1477e-02,  8.7291e-02,  ..., -1.8160e-01,\n",
       "            1.0781e-01, -2.3240e-01],\n",
       "          [-4.0602e-02, -7.9912e-02,  1.1876e-01,  ..., -1.2411e-01,\n",
       "            2.0183e-01, -1.4763e-01],\n",
       "          [ 1.0744e-02, -1.7896e-01,  7.4540e-02,  ..., -1.6393e-01,\n",
       "            2.0912e-01, -1.7105e-01],\n",
       "          ...,\n",
       "          [-1.2411e-01,  1.2644e-01,  2.4801e-02,  ..., -2.3175e-01,\n",
       "           -2.0567e-02, -2.0699e-01],\n",
       "          [-8.1046e-02, -9.7427e-02,  1.5129e-01,  ..., -1.1829e-01,\n",
       "            1.8550e-01, -9.2530e-02],\n",
       "          [-3.0165e-02, -6.1706e-02,  1.6534e-01,  ..., -1.3783e-01,\n",
       "            2.4090e-02, -2.3682e-01]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "arr = [1,3,4,5,9]\n",
    "print(np.eye(10)[arr])\n",
    "inputs = (batch_size, num_step)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_layer, vocab_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = rnn_layer\n",
    "        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n",
    "        self.character_num = character_num\n",
    "        self.dense = nn.Linear(self.hidden_size, vocab_size)\n",
    "        self.state = None\n",
    "\n",
    "    def forward(self, inputs, state): # inputs: (batch, seq_len)\n",
    "        # 获取one-hot向量表示\n",
    "        X = d2l.to_onehot(inputs, self.vocab_size) # X是个list\n",
    "        Y, self.state = self.rnn(torch.stack(X), state)\n",
    "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n",
    "        # 形状为(num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.view(-1, Y.shape[-1]))\n",
    "        return output, self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): RNN(30, 256)\n",
       "  (dense): Linear(in_features=256, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(rnn_layer, character_num)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "# 定义损失器和梯度下降\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 500 # 训练次数\n",
    "for epoch in range(num_epoches):\n",
    "    # X = X.to(device)\n",
    "    # Y = \n",
    "    # outputs = model()\n",
    "    loss = criterion(outputs, lables)\n",
    "    \n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print('Epoch: [{}/{}], Step:[{}/{}], Loss:{}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
