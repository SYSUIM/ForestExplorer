{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 神经网络\n",
    "> written by panzy25\n",
    "\n",
    "用于搭建带有时间序列的文本信息，输出相关特征向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入pytorch模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批次，公司个数\n",
    "batch_size = 3999\n",
    "# 时间长度\n",
    "seq_len = 8\n",
    "# 单个公司特征个数\n",
    "input_size = 16\n",
    "# 隐层size\n",
    "hidden_size = 15\n",
    "# RNN层数\n",
    "num_layers = 1\n",
    "# 学习率\n",
    "learning_rate = 0.0000000001\n",
    "# 输出size\n",
    "output_size = 1\n",
    "# 训练循环次数\n",
    "epoch_num = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入input数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.00000000e+00, 0.00000000e+00, 3.78750125e-02, ...,\n",
       "          3.32764632e-01, 5.02779596e-01, 8.64862643e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.88469863e-02, ...,\n",
       "          1.47936848e-01, 5.28868450e-01, 8.53767217e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.62159011e-02, ...,\n",
       "          1.02379211e-01, 3.94319464e-01, 5.04417454e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.04741595e-02, ...,\n",
       "          6.98348392e-02, 7.89148177e-02, 7.46806292e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.48962656e-02, ...,\n",
       "          6.93856288e-02, 8.07796677e-01, 7.88952664e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.52680653e-02, ...,\n",
       "          1.18200293e-01, 9.12917921e-02, 6.92475428e-01]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 6.03955960e-01, ...,\n",
       "          6.68430511e-02, 5.11619022e-01, 6.92475428e-01],\n",
       "         [2.16800298e-03, 2.25741668e-03, 3.81740257e-02, ...,\n",
       "          3.10251465e-01, 5.02957955e-01, 8.28176847e-01],\n",
       "         [2.48180762e-03, 2.59836399e-03, 4.91175491e-02, ...,\n",
       "          1.28003912e-01, 5.27869965e-01, 5.56891326e-01],\n",
       "         ...,\n",
       "         [1.42342734e-03, 1.56724302e-03, 4.24060433e-01, ...,\n",
       "          8.78131095e-03, 6.09161098e-01, 6.71989642e-01],\n",
       "         [1.45658167e-03, 1.50112155e-03, 7.22068575e-02, ...,\n",
       "          6.90326010e-02, 8.01538631e-02, 9.37460268e-01],\n",
       "         [1.18792565e-03, 1.25479275e-03, 2.55465412e-02, ...,\n",
       "          1.29226323e-01, 8.07894705e-01, 9.82318060e-01]],\n",
       " \n",
       "        [[8.37538445e-04, 8.28286487e-04, 6.51084076e-02, ...,\n",
       "          1.26896356e-01, 9.03580494e-02, 8.52534844e-01],\n",
       "         [1.10890690e-03, 8.79276710e-04, 6.05983015e-01, ...,\n",
       "          9.36335197e-02, 5.01332296e-01, 8.52534844e-01],\n",
       "         [5.60690426e-05, 3.22003881e-05, 3.80344862e-02, ...,\n",
       "          2.97158964e-01, 5.03160889e-01, 9.12710090e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.62159011e-02, ...,\n",
       "          9.94182604e-02, 3.94087471e-01, 2.38613051e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.22230564e-01, ...,\n",
       "          1.01772918e-02, 6.07621477e-01, 1.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.04741595e-02, ...,\n",
       "          6.90426289e-02, 8.00161326e-02, 1.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 4.22230564e-01, ...,\n",
       "          1.07229734e-02, 6.07621477e-01, 5.90512323e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.04741595e-02, ...,\n",
       "          7.19206586e-02, 8.00161326e-02, 8.29930342e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.48962656e-02, ...,\n",
       "          9.28446595e-02, 8.08310693e-01, 9.23615801e-01],\n",
       "         ...,\n",
       "         [2.73626378e-03, 2.25527466e-03, 5.99581786e-01, ...,\n",
       "          4.96705272e-02, 4.98812838e-01, 8.48318272e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.78750125e-02, ...,\n",
       "          2.80135005e-01, 5.02739043e-01, 8.33865033e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.88469863e-02, ...,\n",
       "          1.12681632e-01, 5.27372189e-01, 8.86245164e-01]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 6.62159011e-02, ...,\n",
       "          8.77137980e-02, 3.90949852e-01, 2.38613051e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.22230564e-01, ...,\n",
       "          9.49792904e-03, 6.07621477e-01, 1.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.04741595e-02, ...,\n",
       "          7.25825052e-02, 8.00161326e-02, 1.00000000e+00],\n",
       "         ...,\n",
       "         [8.91887862e-04, 6.85767557e-04, 6.45655714e-02, ...,\n",
       "          1.25124061e-01, 9.21443496e-02, 6.65199741e-01],\n",
       "         [7.99277050e-04, 6.02875375e-04, 6.03465199e-01, ...,\n",
       "          6.28328009e-02, 5.01332296e-01, 6.65199741e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.78750125e-02, ...,\n",
       "          2.85512944e-01, 5.02739043e-01, 8.33865033e-01]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 4.88469863e-02, ...,\n",
       "          1.22648100e-01, 5.27372189e-01, 8.86245164e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.62159011e-02, ...,\n",
       "          9.29564218e-02, 3.94087471e-01, 2.38613051e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.22230564e-01, ...,\n",
       "          1.04227389e-02, 6.07621477e-01, 1.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.48962656e-02, ...,\n",
       "          9.35840559e-02, 8.08310693e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.52680653e-02, ...,\n",
       "          1.27747058e-01, 9.21443496e-02, 6.73457806e-01],\n",
       "         [1.15229108e-02, 1.00545993e-02, 6.13536466e-01, ...,\n",
       "          8.41653355e-02, 5.03033971e-01, 6.73457806e-01]]]),\n",
       " (8, 3999, 16),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "train_x = np.loadtxt('./new32_arr13_20.txt').reshape(8,3999, -1)\n",
    "# train_x.dtype = 'float32'\n",
    "# inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "# train_x.shape, hidden0.shape, train_x\n",
    "train_x, train_x.shape, train_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = train_x[0]\n",
    "# Y = np.arange(0, np.shape(train_x)[0], 1)\n",
    "# X = np.arange(0, np.shape(train_x)[1], 1)\n",
    "# X, Y = np.meshgrid(X, Y)\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection=\"3d\")\n",
    "# ax.plot_surface(X, Y, train_x, cmap=cm.gist_rainbow)\n",
    "# # ax.set_zlim(0, 400)\n",
    "# ax.set_xlabel('Character')\n",
    "# ax.set_ylabel('Batch')\n",
    "# ax.set_zlabel('Scale')\n",
    "# plt.savefig('plo1.png', dpi = 1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入output数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 3999, 1),\n",
       " array([[[   0.],\n",
       "         [1789.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [   0.],\n",
       "         [   0.],\n",
       "         [   0.]],\n",
       " \n",
       "        [[   0.],\n",
       "         [1638.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [   0.],\n",
       "         [   0.],\n",
       "         [   0.]],\n",
       " \n",
       "        [[   0.],\n",
       "         [ 908.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [   0.],\n",
       "         [   0.],\n",
       "         [   0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0.],\n",
       "         [1779.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [   0.],\n",
       "         [   0.],\n",
       "         [   0.]],\n",
       " \n",
       "        [[   0.],\n",
       "         [3206.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [   0.],\n",
       "         [   0.],\n",
       "         [   0.]],\n",
       " \n",
       "        [[   0.],\n",
       "         [2430.],\n",
       "         [   0.],\n",
       "         ...,\n",
       "         [ 152.],\n",
       "         [ -15.],\n",
       "         [ 348.]]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = torch.randn(seq_len, batch_size, 1)\n",
    "# labels.shape, labels\n",
    "# train_y = []\n",
    "train_y = np.loadtxt('./净利润Y/profit13_20.txt').reshape(8,3999, -1)\n",
    "# train_y.dtype = 'float32'\n",
    "train_y.shape, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = train_y[0]\n",
    "# plt.plot(np.linspace(1,3999,3999), train_y ,'ro', label='Original data', c='b', markersize=0.5)\n",
    "# plt.legend()\n",
    "# plt.ylim((0, 600))\n",
    "# plt.xlabel('Batch')\n",
    "# plt.ylabel('Value')\n",
    "# plt.savefig('RNN_train_y.png', dpi = 1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个RNN_Model类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_rnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, num_layers):\n",
    "        super(model_rnn, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn = torch.nn.LSTM(input_size = self.input_size,\n",
    "                               hidden_size = self.hidden_size,\n",
    "                               num_layers = self.num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hidden0 = torch.zeros(self.num_layers,\n",
    "                             self.batch_size,\n",
    "                             self.hidden_size)\n",
    "#         print(hidden0.shape)\n",
    "        out, hidden = self.rnn(inputs, (hidden0,hidden0))\n",
    "        fc_out = self.fc(out)\n",
    "#         print(out.shape, fc_out.shape)\n",
    "#         print(type(out), type(fc_out), type(hidden))\n",
    "#         print(out[0])\n",
    "        # size of hidden: [num_layers, batch_size, hidden_size]\n",
    "        return fc_out\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    \"\"\"\n",
    "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
    "\n",
    "    :param optimizer: optimizer with the gradients to be clipped\n",
    "    :param grad_clip: clip value\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group[\"params\"]:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个简单的循环神经网络：输入维度为10， 输出维度是10， 单层的单向网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_rnn(\n",
       "  (rnn): LSTM(16, 15)\n",
       "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn = model_rnn(input_size, hidden_size, output_size, batch_size, num_layers)\n",
    "# model_rnn(train_x)\n",
    "model_rnn \n",
    "# model_rnn(\n",
    "#   (rnn):RNN(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行测试\n",
    "> 通过 weight_ih_l0 来访问第一层中的 w_{ih}，因为输入 x_{t}是20维，输出是50维，所以w_{ih}是一个50*20维的向量，另外要访问第\n",
    "二层网络可以使用 weight_ih_l1.对于 w_{hh}，可以用 weight_hh_l0来访问，而 b_{ih}则可以通过 bias_ih_l0来访问。当然可以对它\n",
    "进行自定义的初始化，只需要记得它们是 Variable，取出它们的data，对它进行自定的初始化即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义迭代优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_rnn.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-62d1010adb56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-135-eb894bb6a65a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m                              self.hidden_size)\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         print(hidden0.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mfc_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#         print(out.shape, fc_out.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    577\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    578\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
     ]
    }
   ],
   "source": [
    "Loss = []\n",
    "for epoch in range(epoch_num):\n",
    "    optimizer.zero_grad()\n",
    "    inputs = Variable(torch.from_numpy(train_x))\n",
    "    targets = Variable(torch.from_numpy(train_y))\n",
    "    outputs = model_rnn(inputs.double())\n",
    "    loss = criterion(outputs, targets.float())\n",
    "    RMSE = torch.sqrt(loss)\n",
    "    Loss.append(RMSE.item())\n",
    "    loss.backward()\n",
    "#     clip_gradient(optimizer, 0.1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch)%1 == 0: \n",
    "        print('Epoch [%d/%d], Loss: %.5f' \n",
    "               %(epoch+1, epoch_num, loss.item()), RMSE.item())\n",
    "#     print(outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
